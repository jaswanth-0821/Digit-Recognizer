{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-18T11:21:54.417133Z","iopub.execute_input":"2022-07-18T11:21:54.417633Z","iopub.status.idle":"2022-07-18T11:21:54.466921Z","shell.execute_reply.started":"2022-07-18T11:21:54.417537Z","shell.execute_reply":"2022-07-18T11:21:54.465535Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#### Importing Libraries","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\n\n\nsns.set(style='white', context='notebook', palette='deep')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:22:00.544791Z","iopub.execute_input":"2022-07-18T11:22:00.545527Z","iopub.status.idle":"2022-07-18T11:22:08.088867Z","shell.execute_reply.started":"2022-07-18T11:22:00.545492Z","shell.execute_reply":"2022-07-18T11:22:08.087683Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nimport pickle\nfrom joblib import Parallel, delayed\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2022-07-18T12:26:40.553264Z","iopub.execute_input":"2022-07-18T12:26:40.554042Z","iopub.status.idle":"2022-07-18T12:26:40.559825Z","shell.execute_reply.started":"2022-07-18T12:26:40.554006Z","shell.execute_reply":"2022-07-18T12:26:40.558179Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Importing Training data and Testing data from Kaggle","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:22:12.207945Z","iopub.execute_input":"2022-07-18T11:22:12.208663Z","iopub.status.idle":"2022-07-18T11:22:18.047677Z","shell.execute_reply.started":"2022-07-18T11:22:12.208631Z","shell.execute_reply":"2022-07-18T11:22:18.046366Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Printing train data","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:22:22.021222Z","iopub.execute_input":"2022-07-18T11:22:22.022299Z","iopub.status.idle":"2022-07-18T11:22:22.054977Z","shell.execute_reply.started":"2022-07-18T11:22:22.022251Z","shell.execute_reply":"2022-07-18T11:22:22.053652Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Spliting the data\nWe know that to train the model we need both features and values. So we need to get these features and values from the train data we imported. When we oberseve closely in Train data we have 785 columns, which means first column is value and remaining 784 are features for our model. Now we will create two variables one is x_train and other is y_train. These are features and values of our feature set.","metadata":{}},{"cell_type":"code","source":"y_train = train_data[\"label\"]\nx_train = train_data.drop(labels = [\"label\"],axis = 1)\ndel train_data\n\ny_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:27:13.479700Z","iopub.execute_input":"2022-07-18T11:27:13.480140Z","iopub.status.idle":"2022-07-18T11:27:13.606163Z","shell.execute_reply.started":"2022-07-18T11:27:13.480107Z","shell.execute_reply":"2022-07-18T11:27:13.604733Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"we all know how relu and sigmoid activation works ,here is the diagram of relu and sigmoid activation functions\n![data](https://miro.medium.com/max/1400/1*XxxiA0jJvPrHEJHD4z893g.png)\n\nWhen we observe closely the slope of sygmoid curve is decreasing as the value is increasing, so it is very difficult to train the data which as high values because when the slope is less the learning rate also slow which takes more steps to reach optimum, even in \nrelu curve for higher values the learning rate is very high which will also cause problem for us,it will jump too high which will lead to bouncing back to its path or missing the optimum . so to avoid all these we need to set the range of values in between -1 to 1. So what we do is we will normalise the all values so that he values are lie between 0 to 1.","metadata":{}},{"cell_type":"code","source":"x_train = x_train/255.0\ntest_data = test_data/255.0","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:39:05.909773Z","iopub.execute_input":"2022-07-18T11:39:05.910186Z","iopub.status.idle":"2022-07-18T11:39:06.103953Z","shell.execute_reply.started":"2022-07-18T11:39:05.910141Z","shell.execute_reply":"2022-07-18T11:39:06.102710Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.values.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:39:12.447779Z","iopub.execute_input":"2022-07-18T11:39:12.448144Z","iopub.status.idle":"2022-07-18T11:39:12.454832Z","shell.execute_reply.started":"2022-07-18T11:39:12.448114Z","shell.execute_reply":"2022-07-18T11:39:12.453421Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:39:15.554946Z","iopub.execute_input":"2022-07-18T11:39:15.555490Z","iopub.status.idle":"2022-07-18T11:39:15.570512Z","shell.execute_reply.started":"2022-07-18T11:39:15.555440Z","shell.execute_reply":"2022-07-18T11:39:15.569196Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"In Convolutional Neural Networks the output of the model is an array. So we need to change the input values into numpy array let say for example our label is 4 we change that into \n[0,0,0,0,1,0,0,0,0,0] which will also represent the value 4. The output of our model gives the probability of each entry in this array for example our input number is 6 the output of our model will be like [0.0,0.0,0.0,0.0,0.0,0.05,0.6,0.0,0.2,0.15] in which we will consider the position or index which has high probability as our answer.","metadata":{}},{"cell_type":"code","source":"y_train = to_categorical(y_train, num_classes = 10)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:46:31.358357Z","iopub.execute_input":"2022-07-18T11:46:31.358763Z","iopub.status.idle":"2022-07-18T11:46:31.366264Z","shell.execute_reply.started":"2022-07-18T11:46:31.358733Z","shell.execute_reply":"2022-07-18T11:46:31.364772Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Spliting the data\nWe should not use same data for training and validation. So we need to split the data to get both training data and validation data. In our model we are spliting the total data into 0.8 and 0.2 divisons. So that we will get more examples for training the model","metadata":{}},{"cell_type":"code","source":"random_seed = 2\nx_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.1, random_state=random_seed)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:50:41.033269Z","iopub.execute_input":"2022-07-18T11:50:41.033740Z","iopub.status.idle":"2022-07-18T11:50:41.486120Z","shell.execute_reply.started":"2022-07-18T11:50:41.033691Z","shell.execute_reply":"2022-07-18T11:50:41.484743Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"g = plt.imshow(x_train[0][:,:,0])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:50:44.710232Z","iopub.execute_input":"2022-07-18T11:50:44.710945Z","iopub.status.idle":"2022-07-18T11:50:44.998697Z","shell.execute_reply.started":"2022-07-18T11:50:44.710910Z","shell.execute_reply":"2022-07-18T11:50:44.997402Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:50:49.013326Z","iopub.execute_input":"2022-07-18T11:50:49.013734Z","iopub.status.idle":"2022-07-18T11:50:52.546600Z","shell.execute_reply.started":"2022-07-18T11:50:49.013703Z","shell.execute_reply":"2022-07-18T11:50:52.545118Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:51:09.991263Z","iopub.execute_input":"2022-07-18T11:51:09.991732Z","iopub.status.idle":"2022-07-18T11:51:09.998493Z","shell.execute_reply.started":"2022-07-18T11:51:09.991700Z","shell.execute_reply":"2022-07-18T11:51:09.996570Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:51:20.951079Z","iopub.execute_input":"2022-07-18T11:51:20.951677Z","iopub.status.idle":"2022-07-18T11:51:20.968911Z","shell.execute_reply.started":"2022-07-18T11:51:20.951623Z","shell.execute_reply":"2022-07-18T11:51:20.967461Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:51:23.217920Z","iopub.execute_input":"2022-07-18T11:51:23.218364Z","iopub.status.idle":"2022-07-18T11:51:23.224904Z","shell.execute_reply.started":"2022-07-18T11:51:23.218331Z","shell.execute_reply":"2022-07-18T11:51:23.223349Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"epochs = 40 # Turn epochs to 30 to get 0.9967 accuracy\nbatch_size = 86","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:51:25.463238Z","iopub.execute_input":"2022-07-18T11:51:25.463906Z","iopub.status.idle":"2022-07-18T11:51:25.470119Z","shell.execute_reply.started":"2022-07-18T11:51:25.463870Z","shell.execute_reply":"2022-07-18T11:51:25.468453Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:51:28.562338Z","iopub.execute_input":"2022-07-18T11:51:28.562760Z","iopub.status.idle":"2022-07-18T11:51:28.678711Z","shell.execute_reply.started":"2022-07-18T11:51:28.562729Z","shell.execute_reply":"2022-07-18T11:51:28.677416Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"history = model.fit(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val),\n                              verbose = 2, steps_per_epoch=x_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:51:31.348001Z","iopub.execute_input":"2022-07-18T11:51:31.348445Z","iopub.status.idle":"2022-07-18T12:03:52.726827Z","shell.execute_reply.started":"2022-07-18T11:51:31.348371Z","shell.execute_reply":"2022-07-18T12:03:52.725516Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_val)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) ","metadata":{"execution":{"iopub.status.busy":"2022-07-18T12:30:08.294994Z","iopub.execute_input":"2022-07-18T12:30:08.295451Z","iopub.status.idle":"2022-07-18T12:30:08.765883Z","shell.execute_reply.started":"2022-07-18T12:30:08.295398Z","shell.execute_reply":"2022-07-18T12:30:08.764553Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"errors = (y_pred_classes - y_true != 0)\n\nY_pred_classes_errors = y_pred_classes[errors]\nY_pred_errors = y_pred[errors]\nY_true_errors = y_true[errors]\nX_val_errors = x_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T12:30:11.153989Z","iopub.execute_input":"2022-07-18T12:30:11.154521Z","iopub.status.idle":"2022-07-18T12:30:11.905713Z","shell.execute_reply.started":"2022-07-18T12:30:11.154488Z","shell.execute_reply":"2022-07-18T12:30:11.904452Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# predict results\nresults = model.predict(test_data)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T12:30:15.211311Z","iopub.execute_input":"2022-07-18T12:30:15.211811Z","iopub.status.idle":"2022-07-18T12:30:17.295741Z","shell.execute_reply.started":"2022-07-18T12:30:15.211779Z","shell.execute_reply":"2022-07-18T12:30:17.294456Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T12:30:20.448267Z","iopub.execute_input":"2022-07-18T12:30:20.449052Z","iopub.status.idle":"2022-07-18T12:30:20.506051Z","shell.execute_reply.started":"2022-07-18T12:30:20.449014Z","shell.execute_reply":"2022-07-18T12:30:20.504753Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}